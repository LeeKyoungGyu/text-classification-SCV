{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00120adf",
   "metadata": {},
   "source": [
    "# Klue augmentation(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dbc2aa",
   "metadata": {},
   "source": [
    "## 0. 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "03f6cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, TFBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from soynlp.normalizer import *\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8bfcfb",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15dc18a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 피아노 좀 쳐봐.\\n싫어.\\n왜 손가락 없다고 유세 떠는 거야?\\n이씨.\\n비행...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>요즘에는 액수가 작네?\\n미안해 요즘에 용돈이 작아\\n그게 나랑 무슨 상관이야?\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>야 이거봐 완전 길동이 닯음\\n 진짜네 \\n야 그러지마.\\n왜 똑같구만 원숭이 \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이거기 \\n저저희요?\\n그래 거기 너네 둘\\n왜왜요\\n왜요?? 하참나 웃기는 놈들...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>아 이새끼 대답안하는거 보소\\n절대 안해\\n아직도 말할 기운이 있나봐 ? 내가 좀 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>시끄러워 살수가 없어요\\n우리집은 아이도 교육시켜 조용히 걸어요\\n지금도 아이 소리...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>새파랗게 젊은게 어디 여길 앉아있어\\n저 임산부에요\\n사지 멀쩡한게! 임신이 벼슬이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>핸드폰 좋아보인다?\\n누구세요?\\n핸드폰 내놔봐 전화 좀 쓰게\\n죄송해요 급하게 갈...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>왜 살아?\\n 알바야?\\n 아니 나보다 공부도 못하고 잘하는 것도 없잖아\\n 내가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>친구야. 잠깐 스톱.\\n 형들이 집에 가야하는데 차비가 없어.\\n 한 10만원 정도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너가 학교 다닐때 공부 잘했으면 배달일 했겠니?\\n말이 너무 심한거 아냐?\\n뭐가?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>어! 저새끼 뭐야 \\n거기 일로와바 너 어디서 부터 봤어\\n아하나도 못봤어요 \\n야...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>야 우리 사장님 너무 인맥 위주로만 뽑지 않냐 다들 인성이 안된것 같아\\n야 새끼야...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>이번주말에 뭐하나?\\n네????\\n우리어머니가 이번주에 갈빗집을 여는데 처음이라 손...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>이봐 안과장 나랑 회식 해야지\\n앗 부장님 죄송합니다. 어머니가 돌아가셔서 장례식장...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>어머 얘 오랜만이다\\n안녕하세요 잘 지내셨어요?\\n얘 근데 넌 살이 좀 찐것 같다?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class                                       conversation\n",
       "idx                                                                \n",
       "1          일반 대화  오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....\n",
       "2          일반 대화  오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....\n",
       "3      기타 괴롭힘 대화  너 피아노 좀 쳐봐.\\n싫어.\\n왜 손가락 없다고 유세 떠는 거야?\\n이씨.\\n비행...\n",
       "4          갈취 대화  요즘에는 액수가 작네?\\n미안해 요즘에 용돈이 작아\\n그게 나랑 무슨 상관이야?\\n...\n",
       "5      기타 괴롭힘 대화  야 이거봐 완전 길동이 닯음\\n 진짜네 \\n야 그러지마.\\n왜 똑같구만 원숭이 \\n...\n",
       "6          갈취 대화  어이거기 \\n저저희요?\\n그래 거기 너네 둘\\n왜왜요\\n왜요?? 하참나 웃기는 놈들...\n",
       "7          협박 대화  아 이새끼 대답안하는거 보소\\n절대 안해\\n아직도 말할 기운이 있나봐 ? 내가 좀 ...\n",
       "8          협박 대화  시끄러워 살수가 없어요\\n우리집은 아이도 교육시켜 조용히 걸어요\\n지금도 아이 소리...\n",
       "9      기타 괴롭힘 대화  새파랗게 젊은게 어디 여길 앉아있어\\n저 임산부에요\\n사지 멀쩡한게! 임신이 벼슬이...\n",
       "10         갈취 대화  핸드폰 좋아보인다?\\n누구세요?\\n핸드폰 내놔봐 전화 좀 쓰게\\n죄송해요 급하게 갈...\n",
       "11     기타 괴롭힘 대화  왜 살아?\\n 알바야?\\n 아니 나보다 공부도 못하고 잘하는 것도 없잖아\\n 내가 ...\n",
       "12         갈취 대화  친구야. 잠깐 스톱.\\n 형들이 집에 가야하는데 차비가 없어.\\n 한 10만원 정도...\n",
       "13     기타 괴롭힘 대화  너가 학교 다닐때 공부 잘했으면 배달일 했겠니?\\n말이 너무 심한거 아냐?\\n뭐가?...\n",
       "14         협박 대화  어! 저새끼 뭐야 \\n거기 일로와바 너 어디서 부터 봤어\\n아하나도 못봤어요 \\n야...\n",
       "15         일반 대화  오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....\n",
       "16         일반 대화  오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....\n",
       "17   직장 내 괴롭힘 대화  야 우리 사장님 너무 인맥 위주로만 뽑지 않냐 다들 인성이 안된것 같아\\n야 새끼야...\n",
       "18   직장 내 괴롭힘 대화  이번주말에 뭐하나?\\n네????\\n우리어머니가 이번주에 갈빗집을 여는데 처음이라 손...\n",
       "19   직장 내 괴롭힘 대화  이봐 안과장 나랑 회식 해야지\\n앗 부장님 죄송합니다. 어머니가 돌아가셔서 장례식장...\n",
       "20     기타 괴롭힘 대화  어머 얘 오랜만이다\\n안녕하세요 잘 지내셨어요?\\n얘 근데 넌 살이 좀 찐것 같다?..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path =\"../data2/train_add_2.csv\"\n",
    "train_data = pd.read_csv(train_data_path,index_col=0)\n",
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad2f00d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 문단 개수 : 4950\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 문단 개수 :',len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a040fd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['일반 대화', '기타 괴롭힘 대화', '갈취 대화', '협박 대화', '직장 내 괴롭힘 대화'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a40274aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 별 데이터 내용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd1c8312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘 날씨 어때?\n",
      "맑고 따뜻해.\n",
      "좋네! 주말에 계획 있어?\n",
      "등산 갈 생각이야.\n",
      "재밌겠다!\n",
      "최근에 본 영화 있어?\n",
      "아직, 좋은 영화 있어?\n",
      "정말 놀라워! 꼭 봐봐.\n",
      "이번 주말에 볼게.\n",
      "나중에 이야기하자.\n",
      "좋아하는 책 뭐야?\n",
      "'해리 포터' 정말 좋아해.\n",
      "명작이지!\n",
      "넌 어떤 책 좋아해?\n",
      "난 '반지의 제왕' 팬이야.\n",
      "보고서 다 했어?\n",
      "응, 방금 제출했어.\n",
      "완벽한 타이밍이야!\n",
      "발표 준비는?\n",
      "지금 작업 중이야.\n",
      "수학 문제 좀 도와줄래?\n",
      "물론, 어떤 문제야?\n",
      "이 방정식에서 막혔어.\n",
      "같이 풀어보자.\n",
      "고마워, 정말 도움돼.\n"
     ]
    }
   ],
   "source": [
    "print(train_data['conversation'].values[0]) # 일상대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d174de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "너 피아노 좀 쳐봐.\n",
      "싫어.\n",
      "왜 손가락 없다고 유세 떠는 거야?\n",
      "이씨.\n",
      "비행기라도 쳐보라니까? 왜 못치지?\n",
      "하지마.\n",
      "너 내가 볼 땐 의지 문제야. 손가락 없다고 비행기를 못치냐.\n",
      "흑.\n",
      "신발 벗겨줄까? 발로 함 쳐보지 그래?\n",
      "싫어.\n"
     ]
    }
   ],
   "source": [
    "print(train_data['conversation'].values[2]) # 기타 괴롭힘 대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a6e2837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요즘에는 액수가 작네?\n",
      "미안해 요즘에 용돈이 작아\n",
      "그게 나랑 무슨 상관이야?\n",
      "저번에 줬는데 또 필요해?\n",
      "야야야 당연하지 너 지키는 값이 작냐?\n",
      "아니 그건.\n",
      "너 왕따에서 벗어나게 해준게 누구야 나잖아\n",
      "늘 고맙게 생각하는데 이제 그만.\n",
      "다시 왕따속에서 구르고 싶은가봐? 괴롭혀줄까?아니면 돈 가져올래?\n",
      ". 다시 구해올게.\n"
     ]
    }
   ],
   "source": [
    "print(train_data['conversation'].values[3]) # 갈취 대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07377524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아 이새끼 대답안하는거 보소\n",
      "절대 안해\n",
      "아직도 말할 기운이 있나봐 ? 내가 좀 봐주면서 때렸나?\n",
      "쿨럭\n",
      "야 괜히 자존심 피우다가 지금보다 더 쳐맞는다?\n",
      "그래도 싫어\n",
      "하 어이가 옆에 야 잘잡아라 빗나가면 니네가 맞는다\n",
      " 알겠어\n",
      "그만해.\n",
      "그만 하고 싶으면 내가 묻는 말에 대답 착실히 하면 되지?\n",
      "그럴일은 없어.내가 여기서 나가면 니네 가만 안둘거야\n",
      "아 진짜 아직도 입만 살아서 너는 죽어도 입만 물에 뜰것같다 오늘 한번 해볼까?입만 뜨는지?\n",
      "여기서 멈춰줘\n"
     ]
    }
   ],
   "source": [
    "print(train_data['conversation'].values[6]) # 협박 대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "804c958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "야 우리 사장님 너무 인맥 위주로만 뽑지 않냐 다들 인성이 안된것 같아\n",
      "야 새끼야 뒤에서 내 이야기를 뭘 그렇게 쑥덕거려 미친것아 너희 해고야!\n",
      "아니 사장님 그렇다고 해고까지 주실 필요는 없잖아요\n",
      "너 인맥 위주 싫다며 그런 사상도 안된놈이 뭔 우리 회사를 다녀\n",
      "아니 사장님 제가 틀린말을 했나요? 너무 인맥 위주로만 뽑으니까 회사가 성적이 안나오죠\n",
      "야 너 나한테 대들어 미친새끼야\n",
      "아니 뭐 해고라니 그냥 당당히 노동청에다 알릴게요\n",
      "알린다고 한들 너 주장 뿐인데 모든 증거는 다 입막음 되어있어 어디 전문변호사 고용해서 한판해봐?\n",
      "죄송합니다.\n",
      "입닥치고 넌 퇴직금도 없는줄 알아 완전 간이 부은 놈아니야\n"
     ]
    }
   ],
   "source": [
    "print(train_data['conversation'].values[16]) # 직장 내 괴롭힘 대화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224df47b",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비 (Data preparation)\n",
    "### 2.1-1 전처리 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92523cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    emoticon_normalize(sentence)\n",
    "    repeat_normalize(sentence)\n",
    "    sentence = re.sub(r'([^a-zA-Zㄱ-ㅎ가-힣?.!,])', \" \", sentence)\n",
    "    sentence = re.sub(r'!+', '!', sentence)\n",
    "    sentence = re.sub(r'\\?+', '?', sentence)\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.replace(\"\\n\", \" \")\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9feaad8",
   "metadata": {},
   "source": [
    "### 2.1-2 전처리 함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afd6cd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4950/4950 [00:01<00:00, 3194.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# 학습할 문장이 담길 배열\n",
    "sentences = []\n",
    "\n",
    "for val in tqdm(train_data['conversation']):\n",
    "    sentences.append(preprocess_sentence(val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406ee77",
   "metadata": {},
   "source": [
    "### 2.2 최대 길이 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6452359",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a526d7",
   "metadata": {},
   "source": [
    "### 2.3 class(label) 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40aae6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "CLASS_NAMES = ['협박 대화', '갈취 대화', '직장 내 괴롭힘 대화', '기타 괴롭힘 대화','일반 대화']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(CLASS_NAMES)\n",
    "\n",
    "train_data['class'] = encoder.transform(train_data['class'])\n",
    "labels = train_data['class']\n",
    "\n",
    "len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "302ce813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {'협박 대화': 4, '갈취 대화': 0, '직장 내 괴롭힘 대화': 3, '기타 괴롭힘 대화': 1, '일반 대화': 2}\n"
     ]
    }
   ],
   "source": [
    "class_mapping = {class_name: encoder.transform([class_name])[0] for class_name in CLASS_NAMES}\n",
    "print(\"Class mapping:\", class_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4d347239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
    "    \n",
    "    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n",
    "    \n",
    "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
    "        # input_id는 워드 임베딩을 위한 문장의 정수 인코딩\n",
    "        input_id = tokenizer.encode(example, \n",
    "                                    max_length=max_seq_len, \n",
    "                                    pad_to_max_length=True,\n",
    "                                   )\n",
    "        \n",
    "        # attention_mask는 실제 단어가 위치하면 1, 패딩의 위치에는 0인 시퀀스\n",
    "        padding_count = input_id.count(tokenizer.pad_token_id)\n",
    "        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
    "        \n",
    "        # token_type_id은 세그먼트 인코딩\n",
    "        token_type_id = [0] * max_seq_len\n",
    "        \n",
    "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
    "        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        data_labels.append(label)\n",
    "    \n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "    \n",
    "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
    "    \n",
    "    return (input_ids, attention_masks, token_type_ids), data_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972a48d",
   "metadata": {},
   "source": [
    "### 2.4 train-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "24f151ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    sentences, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c035fff",
   "metadata": {},
   "source": [
    "## 3. 모델\n",
    "### 3.1-1 토크나이저 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f6ec39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# klue model\n",
    "model_name = \"klue/bert-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ebd8a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT 토크나이저와 모델 준비\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0225ec71",
   "metadata": {},
   "source": [
    "### 3.1-2 토크나이저 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "28e6d688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3960/3960 [00:03<00:00, 995.94it/s] \n",
      "100%|██████████| 990/990 [00:00<00:00, 1014.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋을 BERT 입력 형식으로 변환\n",
    "X_train, y_train = convert_examples_to_features(\n",
    "    X_train, y_train, \n",
    "    max_seq_len=MAX_LEN, tokenizer=tokenizer\n",
    ")\n",
    "X_valid, y_valid = convert_examples_to_features(\n",
    "    X_valid, y_valid, \n",
    "    max_seq_len=MAX_LEN, tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3db58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBertForMultiClassClassification(tf.keras.Model):\n",
    "    def __init__(self, model_name, num_classes, dropout_rate=0.1):\n",
    "        super(TFBertForMultiClassClassification, self).__init__()\n",
    "        self.bert = TFBertModel.from_pretrained(model_name, from_pt=True)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes,\n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n",
    "                                                kernel_regularizer=l2(0.01),\n",
    "                                                activation='softmax',\n",
    "                                                name='classifier')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_ids, attention_mask, token_type_ids = inputs\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "        cls_token = outputs[1]\n",
    "        dropped = self.dropout(cls_token)\n",
    "        prediction = self.classifier(dropped)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0f6835",
   "metadata": {},
   "source": [
    "### 3.2 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1f812e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['bert.embeddings.position_ids', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForMultiClassClassification(model_name, num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b097b71",
   "metadata": {},
   "source": [
    "### 3.3 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e71bfd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "lr = 5e-5\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce3cc2a",
   "metadata": {},
   "source": [
    "### 3.4 TF 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e239a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TensorFlow 데이터셋 생성\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#     dict(train_encodings),\n",
    "#     train_labels\n",
    "# )).shuffle(100).batch(BATCH_SIZE)\n",
    "\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#     dict(val_encodings),\n",
    "#     val_labels\n",
    "# )).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0c3a6c",
   "metadata": {},
   "source": [
    "### 3.5 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bfd846f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b3abed",
   "metadata": {},
   "source": [
    "### 3.6 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea3b388",
   "metadata": {},
   "source": [
    "### 3.6-1 콜백 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "87d9cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # 검증 손실을 모니터링\n",
    "    patience=3,            # 3 에포크 동안 개선되지 않으면 중지\n",
    "    restore_best_weights=True  # 최상의 가중치를 복원\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model_weights.h5',  # 모델 가중치를 저장할 파일 경로\n",
    "    monitor='val_loss',        # 검증 손실을 모니터링\n",
    "    save_best_only=True,       # 최상의 모델만 저장\n",
    "    save_weights_only=True,   # 저장 (가중치)\n",
    "    mode='min',                # 'val_loss'가 최소일 때 저장\n",
    "    verbose=1                  # 저장 시 로그 출력\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e90974f",
   "metadata": {},
   "source": [
    "### 3.6-2 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "073b9331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "124/124 [==============================] - 185s 1s/step - loss: 0.3751 - accuracy: 0.9038 - val_loss: 0.3139 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31388, saving model to best_model_weights.h5\n",
      "Epoch 2/10\n",
      "124/124 [==============================] - 168s 1s/step - loss: 0.1938 - accuracy: 0.9677 - val_loss: 0.3455 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31388\n",
      "Epoch 3/10\n",
      "124/124 [==============================] - 168s 1s/step - loss: 0.1286 - accuracy: 0.9879 - val_loss: 0.4147 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31388\n",
      "Epoch 4/10\n",
      "124/124 [==============================] - 168s 1s/step - loss: 0.1137 - accuracy: 0.9891 - val_loss: 0.5486 - val_accuracy: 0.8939\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7e25aa5439d0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs=EPOCH,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55931f59",
   "metadata": {},
   "source": [
    "### 3.7 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1fbabee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 13s 428ms/step - loss: 0.3139 - accuracy: 0.9162\n",
      "평가 결과: [0.31387799978256226, 0.9161615967750549]\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "evaluation = model.evaluate(X_valid, y_valid)\n",
    "print(\"평가 결과:\", evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5d7f9",
   "metadata": {},
   "source": [
    "### 3.8 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dcc38099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def score(model, val):\n",
    "    X, y = val\n",
    "    # 실제 예측값 생성\n",
    "    real_predictions = model.predict(X)\n",
    "\n",
    "    # 예측값을 레이블로 변환\n",
    "    real_predicted_labels = np.argmax(real_predictions, axis=1)\n",
    "\n",
    "    # 정확도 계산\n",
    "    real_accuracy = accuracy_score(y, real_predicted_labels)\n",
    "    print(f\"Real Accuracy: {real_accuracy:.4f}\")\n",
    "\n",
    "    # 분류 보고서 생성\n",
    "    real_report = classification_report(y, real_predicted_labels, target_names=[f\"Class {i}\" for i in range(5)])\n",
    "    print(real_report)\n",
    "\n",
    "    # F1 스코어 계산\n",
    "    real_f1 = f1_score(y, real_predicted_labels, average='weighted')\n",
    "    print(f\"\\nWeighted F1 Score (based on real predictions): {real_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ab4f4b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Accuracy: 0.9162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.84      0.90      0.87       191\n",
      "     Class 1       0.88      0.91      0.89       223\n",
      "     Class 2       1.00      1.00      1.00       191\n",
      "     Class 3       0.96      0.95      0.96       200\n",
      "     Class 4       0.90      0.82      0.86       185\n",
      "\n",
      "    accuracy                           0.92       990\n",
      "   macro avg       0.92      0.92      0.92       990\n",
      "weighted avg       0.92      0.92      0.92       990\n",
      "\n",
      "\n",
      "Weighted F1 Score (based on real predictions): 0.9161\n"
     ]
    }
   ],
   "source": [
    "score(model, (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c564aa18",
   "metadata": {},
   "source": [
    "## 4. 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "31e705f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "test_data_path = \"../data/test.json\"\n",
    "\n",
    "test = pd.read_json(test_data_path).transpose()\n",
    "\n",
    "# with open(test_data_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "#     test = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "51776b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text\n",
      "t_000  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...\n",
      "t_001  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...\n",
      "t_002  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...\n",
      "t_003  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...\n",
      "t_004  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...\n"
     ]
    }
   ],
   "source": [
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "824bae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_predict = []\n",
    "\n",
    "for idx, value in test.iterrows():\n",
    "\n",
    "    test_sentence = value[\"text\"]\n",
    "    \n",
    "    test_encodings = tokenizer(test_sentence, truncation=True, padding=\"max_length\", max_length=MAX_LEN, return_tensors=\"tf\")\n",
    "\n",
    "    test_predictions = model.predict(\n",
    "        (test_encodings[\"input_ids\"],\n",
    "            test_encodings[\"attention_mask\"],\n",
    "            test_encodings[\"token_type_ids\"])\n",
    "    )\n",
    "    test_class_probabilities = tf.nn.softmax(test_predictions, axis=-1).numpy() # [[0.13297564 0.8358507  0.00801584 0.02315779]]\n",
    "    test_predicted_class = np.argmax(test_class_probabilities, axis=1) # [ 1 ]\n",
    "    test_predict.append(test_predicted_class[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1b65799a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0dbfe512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 3, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_predict[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9d2570f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name class\n",
       "0     t_000    01\n",
       "1     t_001    03\n",
       "2     t_002    03\n",
       "3     t_003    02\n",
       "4     t_004    02"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {'협박 대화': 4, '갈취 대화': 0, '직장 내 괴롭힘 대화': 3, '기타 괴롭힘 대화': 1, '일반 대화': 2}\n",
    "\n",
    "def labelnum_to_text(x):\n",
    "    if x == 0:\n",
    "        return '01'\n",
    "    if x == 1:\n",
    "        return '02'\n",
    "    if x == 2:\n",
    "        return '04'\n",
    "    if x == 3:\n",
    "        return '03'\n",
    "    if x == 4:\n",
    "        return '00'\n",
    "    \n",
    "submission = pd.DataFrame({\"file_name\":test.index, 'class':test_predict})\n",
    "\n",
    "submission['class'] = submission['class'].apply(labelnum_to_text)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d43e5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../sub/base_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3af0091b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  class\n",
       "0     t_000      1\n",
       "1     t_001      3\n",
       "2     t_002      3\n",
       "3     t_003      2\n",
       "4     t_004      2"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../sub/base_sub.csv\").head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
